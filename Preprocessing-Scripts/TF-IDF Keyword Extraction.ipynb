{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Keyword Extraction - TF-IDF</h2>\n",
    "\n",
    "Author: Joshua White\n",
    "\n",
    "This notebook will contain code used extract keywords from pandas series for model creation for my CSCE 799 Expirment and my CSCE 623 Project. The example input file, 'nyc-jobs-cleaned.csv', has already had some pre-processing done to the 'job description' column, and we will be using TF-IDF to extract key words from this column.\n",
    "\n",
    "Source: https://kavita-ganesan.com/extracting-keywords-from-text-tfidf/#.XpRvAVNKi8U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start out with some imports \n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "\n",
    "#Set up the pandas frame on an already preprocessed file\n",
    "DFrame = pd.read_csv('training_set_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is old code but I'm leaving in the function declaration in case it's necessary later. \n",
    "#Right now our 'job_description' column is a column of lists, and we just want it \n",
    "#to be a column of strings. We will transform it here\n",
    "def convert_to_text(text):\n",
    "    return ' '.join(text)\n",
    "\n",
    "#Now we will make a new column called 'jd_text' and run the function on it\n",
    "#DFrame['jd_text'] = DFrame['job_description'].apply(lambda x: convert_to_text(x))\n",
    "#DFrame['jd_text'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will create a vocabulary of words from the job_description column.\n",
    "#You can choose to ignore words that appear in some % of the documents here\n",
    "cv = CountVectorizer(max_df = 0.85)\n",
    "word_count_vector = cv.fit_transform(DFrame['processed_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can take a look at how many words we are working with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1328, 5483)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_vector.shape #The second number will be the size of the vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to limit the words we are working with we could easily change this by setting max_features = 'size' in the CountVectorizer call, lets raise the threshold to the most frequent 10,000 words.  \n",
    "  \n",
    "The cv.fit_transform(...) creates the vocabulary and returns a term-document matrix, which is what we are looking for. Each column in this matrix represents a word in the vocabulary while each row represents a document, in this example a document is just the job description text, in our dataset where the values in this case are word counts. In this representation, counts of some words could be 0 if the word did not appear in the corresponding document.  \n",
    "\n",
    "If you wanted you could also filter out stop words in the CountVectorizer call by including (..., stop_words = <list_of_stop_words>, ...) as a parameter. \n",
    "\n",
    "Remember after this the size of the matrix will be a 1661 x 'max_features'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_df = 0.85, max_features = 10000)\n",
    "word_count_vector = cv.fit_transform(DFrame['processed_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can take a quick look at some of the words in our vocabulary to make sure it makes sense with the following code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['plumbing',\n",
       " 'engineer',\n",
       " 'please',\n",
       " 'read',\n",
       " 'posting',\n",
       " 'carefully',\n",
       " 'make',\n",
       " 'certain',\n",
       " 'meet',\n",
       " 'minimum']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(cv.vocabulary_.keys())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to compute the IDF values. We are going to take the matrix we made from CountVectorizer and generate the IDF. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Imports\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "tfidf_transformer.fit(word_count_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the IDF we can compute the TF-IDF value for a \"document\" (whatever we point it at), and get the vector of TF-IDF scores. Then we sort the words in the vector in descending order of TF-IDF values and iterate over it one more time to extract the top-n keywords for each \"document\" (in this case it's the job description text). \n",
    "\n",
    "First we need to define some functions, I'm just going to copy these functions from the article:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function sorts the values in the vector while preserving the column index\n",
    "def sort_coo(coo_matrix):\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
    "\n",
    "# This function gets the feature names and tf-idf score of top n items\n",
    "def extract_topn_from_vector(feature_names, sorted_items, topn=20):\n",
    "    #use only topn items from vector\n",
    "    sorted_items = sorted_items[:topn]\n",
    " \n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "    \n",
    "    # word index and corresponding tf-idf score\n",
    "    for idx, score in sorted_items:\n",
    "        \n",
    "        #keep track of feature name and its corresponding score\n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_names[idx])\n",
    " \n",
    "    #create a tuples of feature,score\n",
    "    #results = zip(feature_vals,score_vals)\n",
    "    results= {}\n",
    "    for idx in range(len(feature_vals)):\n",
    "        results[feature_vals[idx]]=score_vals[idx]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will try to get the top-n terms from each job description. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    plumbing engineering design project phase cons...\n",
       "1    homeless aside housing set rental restriction ...\n",
       "2    distribute equipment supply stock mail materia...\n",
       "3    metal welding wearing burning mechanic face eq...\n",
       "4    investment estate real portfolio asset committ...\n",
       "5    eligibility federal child information liaison ...\n",
       "6    environmental direction facility research trea...\n",
       "7    payment vendor fiscal provider someone supervi...\n",
       "8    inspector investigative investigation general ...\n",
       "9    water accountable submittal engineering meetin...\n",
       "Name: keywords, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you only need to do this once, this is a mapping of index\n",
    "feature_names=cv.get_feature_names()\n",
    " \n",
    "\n",
    "def generate_keywords(text):\n",
    "    #generate tf-idf for the given document\n",
    "    tf_idf_vector=tfidf_transformer.transform(cv.transform([text]))\n",
    "    \n",
    "    #sort the tf-idf vectors by descending order of scores\n",
    "    sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
    "    \n",
    "    #extract only the top n; n here is 10\n",
    "    keywords = extract_topn_from_vector(feature_names, sorted_items, 20)\n",
    "    \n",
    "    # The {} mean's that the thing is a dictionary list, and we just want strings, so use this code. \n",
    "    # Source: https://stackoverflow.com/questions/16819222/how-to-return-dictionary-keys-as-a-list-in-python\n",
    "    list_of_keywords = list(keywords.keys())\n",
    "    list_of_keywords = convert_to_text(list_of_keywords)\n",
    "    return list_of_keywords\n",
    "\n",
    "DFrame['keywords'] = DFrame['processed_text'].apply(lambda x: generate_keywords(x))\n",
    "DFrame['keywords'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the dataframe here:\n",
    "DFrame.to_csv(r'C:\\Users\\Joshua\\Google Drive\\Thesis Work\\Python\\training_set__keywords.csv', index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
